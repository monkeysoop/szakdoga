{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plot_utils import plot_images, plot_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_path = os.path.join(\"benchmarks\", \"visual\")\n",
    "\n",
    "baseline_file_path = os.path.join(visual_path, \"screenshot_baseline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_image_bgr = cv2.imread(baseline_file_path)\n",
    "baseline_image_rgb = cv2.cvtColor(baseline_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "baseline_image_gray = cv2.cvtColor(baseline_image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "print(baseline_image_rgb.shape)\n",
    "\n",
    "plt.imshow(baseline_image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_filenames = {}\n",
    "\n",
    "for dir_name in os.listdir(visual_path):\n",
    "    sub_dir_path = os.path.join(visual_path, dir_name)\n",
    "    if (os.path.isdir(sub_dir_path)):\n",
    "        benchmark_filenames[dir_name] = os.listdir(sub_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_images = {}\n",
    "\n",
    "for method, filenames in benchmark_filenames.items():\n",
    "    folder_path = os.path.join(visual_path, method)\n",
    "\n",
    "    benchmark_images[method] = []\n",
    "    for filename in filenames:\n",
    "        if (filename.split(\".\")[-1] == \"png\"):\n",
    "            benchmark_file_path = os.path.join(folder_path, filename)\n",
    "            benchmark_image_bgr = cv2.imread(benchmark_file_path)\n",
    "            max_iteration_count = int((os.path.basename(benchmark_file_path).split(\".\")[-2]).split(\"_\")[-1])\n",
    "            benchmark_images[method].append((max_iteration_count, benchmark_image_bgr))\n",
    "\n",
    "    benchmark_images[method].sort(key=lambda x: x[0])\n",
    "\n",
    "benchmark_images = dict(sorted(benchmark_images.items(), key=lambda x: x[0])[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_images_rgb = {}\n",
    "benchmark_images_ssim_diff_gray = {}\n",
    "ssim_scores = {}\n",
    "max_iteration_counts = set()\n",
    "\n",
    "for y, (method, images) in enumerate(benchmark_images.items()):\n",
    "    benchmark_images_rgb[method] = []\n",
    "    benchmark_images_ssim_diff_gray[method] = []\n",
    "    ssim_scores[method] = []\n",
    "\n",
    "    for x, (max_iteration_count, image_bgr) in enumerate(images):\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        (ssim_score, image_ssim_diff_gray) = ssim(baseline_image_gray, image_gray, full=True, data_range=10)\n",
    "        \n",
    "        benchmark_images_rgb[method].append(image_rgb)\n",
    "        benchmark_images_ssim_diff_gray[method].append(image_ssim_diff_gray)\n",
    "        ssim_scores[method].append(round(ssim_score, 3))\n",
    "        max_iteration_counts.add(max_iteration_count)\n",
    "\n",
    "max_iteration_counts = sorted(max_iteration_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(\n",
    "    images=np.array(list(benchmark_images_rgb.values())),\n",
    "    row_labels=[\" \".join(str(i).split(\"_\")) for i in list(benchmark_images_rgb.keys())],\n",
    "    col_labels=[str(i) for i in list(max_iteration_counts)],\n",
    "    figsize=15,\n",
    "    x_label=\"Max iteration count\",\n",
    "    y_label=\"Tracing method\",\n",
    "    title=\"Tracing methods at different max iteration counts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(\n",
    "    images=np.array(list(benchmark_images_ssim_diff_gray.values())),\n",
    "    row_labels=[\" \".join(str(i).split(\"_\")) for i in list(benchmark_images_ssim_diff_gray.keys())],\n",
    "    col_labels=[str(i) for i in list(max_iteration_counts)],\n",
    "    figsize=15,\n",
    "    x_label=\"Max iteration count\",\n",
    "    y_label=\"Tracing method\",\n",
    "    title=\"SSIM error of different tracing methods at different max iteration counts compared to baseline image\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    matrix=np.array(list(ssim_scores.values())),\n",
    "    row_labels=[\" \".join(str(i).split(\"_\")) for i in list(ssim_scores.keys())],\n",
    "    col_labels=[str(i) for i in list(max_iteration_counts)],\n",
    "    meassurment_unit=\"\",\n",
    "    x_figsize=15,\n",
    "    y_figsize=6,\n",
    "    x_label=\"Max iteration count\",\n",
    "    y_label=\"Tracing method\",\n",
    "    title=\"SSIM scores compared to baseline image\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
